import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import joblib

print("ðŸ§  Iniciando treinamento AVANÃ‡ADO de InteligÃªncia ClÃ­nica (V5)...")

# 1. Carregar Dados
try:
    df = pd.read_csv('Obesity.csv')
    # Tratamento de separador caso necessÃ¡rio
    if len(df.columns) < 2: df = pd.read_csv('Obesity.csv', sep=';')
except Exception as e:
    print(f"âŒ Erro ao ler CSV: {e}")
    exit()

# 2. PreparaÃ§Ã£o dos Dados
# IMPORTANTE: NÃ£o criamos a coluna 'Risk_Interaction' (IMC).
# Deixamos o modelo descobrir as relaÃ§Ãµes sozinho.

target_col = 'NObeyesdad'
if target_col not in df.columns: 
    target_col = 'Obesity' # Fallback para outros nomes comuns

# NormalizaÃ§Ã£o de nomes de colunas
if 'family_history_with_overweight' in df.columns:
    df = df.rename(columns={'family_history_with_overweight': 'family_history'})

X = df.drop(columns=[target_col])
y = df[target_col]

# 3. DefiniÃ§Ã£o de Features (Foco Multidimensional)
# Removemos Risk_Interaction e mantemos o foco nos hÃ¡bitos + biometria pura
categorical_features = ['Gender', 'family_history', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']
numerical_features = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']

# ValidaÃ§Ã£o se as colunas existem
missing_cols = [col for col in categorical_features + numerical_features if col not in X.columns]
if missing_cols:
    print(f"âš ï¸ Aviso: Colunas faltando no CSV: {missing_cols}")

# 4. Pipeline de Processamento Robusto
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

# 5. Modelo (Random Forest Otimizado)
# max_depth=15 evita overfitting (decorar o peso exato)
# class_weight='balanced' ajuda a nÃ£o ignorar classes menores
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        n_estimators=300, 
        max_depth=15, 
        random_state=42, 
        class_weight='balanced',
        n_jobs=-1
    ))
])

# 6. Treinamento
print("âš™ï¸  Treinando a IA para cruzar HÃ¡bitos x Biometria...")
model_pipeline.fit(X, y)

# 7. Prova Real: O que a IA estÃ¡ olhando?
print("\nðŸ“Š FATORES MAIS IMPORTANTES PARA A DECISÃƒO DA IA:")
try:
    # ExtraÃ§Ã£o tÃ©cnica para mostrar a importÃ¢ncia das features
    feature_names_num = numerical_features
    feature_names_cat = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)
    all_features = np.r_[feature_names_num, feature_names_cat]
    
    importances = model_pipeline.named_steps['classifier'].feature_importances_
    
    df_imp = pd.DataFrame({'Fator': all_features, 'Importancia': importances})
    print(df_imp.sort_values('Importancia', ascending=False).head(10).to_string(index=False))
except Exception as e:
    print(f"(NÃ£o foi possÃ­vel gerar a tabela de importÃ¢ncias: {e})")

# 8. Salvar os CÃ©rebro Novo
joblib.dump(model_pipeline, 'best_obesity_model.pkl')
joblib.dump(model_pipeline, 'full_pipeline_v4.pkl') # Mantendo nome para compatibilidade
print("\nâœ… SUCESSO! Novo modelo focado em comportamento salvo.")